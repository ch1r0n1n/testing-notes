RECON:
	1. Subfinder
		a. Subfinder -d [domain] -o [output]
	2. AssetFinder
		a. Assetfinder --subs-only [domain] > [output]
	3. Subcert
		a. python3 subcert.py -d cengage.com -o subcert_cengage.txt
	4. AMASS
		a. amass enum -brute -active -d cengage.com -o amass-output.txt
FIND LIVE DOMAINS:
	1. HTTProbe
		a. Cat [domain list] | httprobe
		b. Cat amass-output.txt | httprobe -p http:81 -p http:3000 -p https:3000 -p http:3001 -p https:3001 -p http:8000 -p http:8080 -p https:8443 -c 50 | tee online-domains.txt
	2. HTTPX
		a. cat online-domains.txt | httpx -status-code -o httpx.txt | grep 200
		b. Cat online-domains.txt | httpx -status-code 
		c. cat subdomains.txt | httpx -o live-subdomains.txt
URL GATHERING:
	1. GOSPIDER
		a. gospider -S subdomains.txt -o output -c 10 -d 5
	2. GAU
		a. Gau -subs [domain] -o [Output]
		b. cat domains.txt | ~/go/bin/gau -t 5
		c. Gau[domain] |grep -iE '\.js'|grep -ivE '\.json'|sort -u  >> paypalJS.txt
		d. gau [domain] |grep -iE '\.js'|grep -ivE '\.json'|sort -u  >> paypalJS.txt
	3. WAYBACKURLS:
		a. Echo '[URL]' | waybackurls > wayback
		b. Use wc -l to get the amount of lines in a file.
		c. cat live.txt | waybackurls > wayback
		d. cat live.txt | ~/go/bin/waybackurls > waybac
	4. NUCLEI:
		a. Check for low hanging fruit with Nuclei
			a.  nuclei -l [target urlS list] -t /root/Desktop/tools/Nuclei-Templates/
JAVASCRIPT GATHERING:
	1. Collect JS files & use LinkFinder to get endpoints
	2. SECRETFINDER:
		a. Analyzing an entire domain and its JS files:
		b. python3 SecretFinder.py -i https://example.com/ -e
	3. LINKFINDER:
		a. Run LinkFinder to find more endpoints / relative-url-extractor
		b. python linkfinder.py -i https://example.com/1.js -o results.html
		c. Most basic usage to find endpoints in an online JavaScript file and output the HTML results to results.html:
			1. python linkfinder.py -i https://example.com/1.js -o results.html
		d. Enumerating an entire folder for JavaScript files, while looking for endpoints starting with /api/ and finally saving the results to results.html:
			1. python linkfinder.py -i 'Desktop/*.js' -r ^/api/ -o results.html
		e. Analyzing an entire domain and its JS files:
			1. python linkfinder.py -i https://example.com -d
		f. Append the discovered endpoints discovered to the domain.
		g. Attempt to add discovered parameters to the url.
		h. Run nmap to find open ports and services. Figure how to exploit them. 
		i. After we pick our target, spend a day on EACH SUBDOMAIN!
		j. We have to be consistent with a single target if we want to find legit bugs!
		k. Focus on exploiting manually and less with tools. 
		l. This builds our skill set WAY easier than relying on tools.
	4. JSFScan.sh
		a. ./JSFScan.sh -l target.txt --all -r -o [OUTPUT DIRECTORY]
	5. FUZZING WITH FFUF:
		a. Fuzz directories and parameters
		b. Fuzz accepted symbols
		c. Fuzz encodings
PARAMETER MINING FOR THE FOLLOWING:
	1. OPEN REDIRECT
	2. SSRF
	3. XXE
	4. XXS / KNOXSS
GF:
	1. Gather URLS from target[s]
	2. Navigate to ParamSpider output folder
	3. python3 paramspider.py --domain hackerone.com --exclude php,jpg --output hackerone.txt
	4. gf redirect domain.txt //for potential open redirect/SSRF parameters
	5. gf xss domain.txt //for potential xss vulnerable parameters
	6. gf potential domain.txt //for xss + ssrf + open redirect parameters
	7. gf wordpress domain.txt //for wordpress urlS
