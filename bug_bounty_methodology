RECON:
RECON ONE-LINERS:
	1. Echo [domain] | subfinder -silent | httpx -silent| cariddi -intensive | tee results.txt
SUBFINDER
	a. Subfinder -d [domain] -o [output]
ASSETFINDER
	a. Assetfinder --subs-only [domain] > [output]
SUBCERT
	a. python3 subcert.py -d cengage.com -o subcert_cengage.txt
AMASS
	1. amass enum -brute -active -d cengage.com -o amass-output.txt


SORT SUBDOMAINS:
COMBINE ALL THE SUBDOMAINS AND SORT THEM: Look for weird names. Focus on these!!! 
	â€¢ Staging, Dev, Payment, internal, qa, backup, and other uncommon names.
	1. Cat [subfinder] >> domains.txt
	2. Cat [assetfinder] >> domains.txt
	3. Cat [amass-output] >> domains.txt
	4. Cat domains.txt | sort -u | tee unique_domains.txt


DETERMINE LIVE SUBDOMAINS:
HTTPROBE
	a. Cat [domain list] | httprobe
	b. Cat amass-output.txt | httprobe -p http:81 -p http:3000 -p https:3000 -p http:3001 -p https:3001 -p http:8000 -p http:8080 -p https:8443 -c 50 | tee online-domains.txt
HTTPX
	1. cat online-domains.txt | httpx -status-code -o httpx.txt | grep 200
	2. Cat online-domains.txt | httpx -status-code 
	3. cat subdomains.txt | httpx -o live-subdomains.txt


SCREENSHOT SUBDOMAINS:
AQUATONE
	1. Cat live.txt | aquatone

DETECT WAF:
WAFW00F
	1. Wafw00f -i [domains list]
	2. Wafw00f [URL]


NUCLEI FOR LOW-HANGING FRUIT:
	1. nuclei -l [target urlS list] -t /root/Desktop/tools/Nuclei-Templates/


DETERMINE SUBDOMAINS TO TEST:
	1. Go through subdomain list and find uniquely named domains.

CONTENT DISCOVERY:
BURP:
	1. Right click hostname => Click Engagement Tools => Discover Content through Burp[This should be step #1 in our methodology]
		a. This gets a listing of all the directories, files, and parameters Burp can locate for us to test. 
	2. Use the Intruder to fuzz parameters / for parameters.

DIRECTORY BUSTING:
FFUF
	1. Ffuf -w [wordlist]:FUZZ -u http://FUZZ.[domain] -o [output]
	2. Ffuf -ac -v -u [URL]/FUZZ -w [wordlist]

GATHER URLS:
	1. gospider -S subdomains.txt -o output -c 10 -d 5
	2. gospider -S live.txt -o output -c 10 -d 3 --subs -q

WAYBACKURLS:
	1. Cat unique_domains.txt | waybackurls >> wayback
	2. Echo '[URL]' | waybackurls > wayback
	3. Use wc -l to get the amount of lines in a file.
	4. cat live.txt | waybackurls > wayback
	5. cat live.txt | ~/go/bin/waybackurls > wayback

GAU
	1. Gau -subs [domain] -o [Output]
	2. cat domains.txt | ~/go/bin/gau -t 5
	3. Gau[domain] |grep -iE '\.js'|grep -ivE '\.json'|sort -u  >> paypalJS.txt
	4. gau [domain] |grep -iE '\.js'|grep -ivE '\.json'|sort -u  >> paypalJS.txt



PARAMETER FUZZING:
FFUF
	1. ffuf -u 'http://MACHINE_IP/sqli-labs/Less-1/?FUZZ=1' -c -w /usr/share/seclists/Discovery/Web-Content/burp-parameter-names.txt -fw 39
	2. ffuf -u 'http://MACHINE_IP/sqli-labs/Less-1/?FUZZ=1' -c -w /usr/share/seclists/Discovery/Web-Content/raft-medium-words-lowercase.txt -fw 39


GF PARAMETERS:
	1. Gather URLS from target[s]
	2. Navigate to ParamSpider output folder
	3. python3 paramspider.py --domain hackerone.com --exclude php,jpg --output hackerone.txt
	4. gf redirect domain.txt //for potential open redirect/SSRF parameters
	5. gf xss domain.txt //for potential xss vulnerable parameters
	6. gf potential domain.txt //for xss + ssrf + open redirect parameters
	7. gf wordpress domain.txt //for wordpress urlS
